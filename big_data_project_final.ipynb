{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "big_data_project_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Spark Installation"
      ],
      "metadata": {
        "id": "2WPB-fSaDzOP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHHFdnOFkFo6",
        "outputId": "3debf728-88e8-409b-da5c-92f242cdf8e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,622 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\u001b[0m\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 3,622 B] [Connecting to archive.ubuntu.com] [Connecting to\u001b[0m\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,490 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,694 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,947 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,133 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [996 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,268 kB]\n",
            "Get:22 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Fetched 12.9 MB in 4s (2,988 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "40 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ],
      "source": [
        "# 1) First: install Java, Spark and and run a local Spark session by just running this on Google Colab:\n",
        "!apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null   # !apt-get --> install java\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz  # !wget  --> download file from url\n",
        "!tar xf spark-3.1.2-bin-hadoop3.2.tgz  # !tar --> like unzip \n",
        "!pip install -q findspark  # !pip  --> instal a package, we cant import a library without installing it first, most libraries that we used were already installed\n",
        "# This are INSTALLATION COMMANDS IN LINUX that we run in our collab space, it's similar to downloading programs an installing them on our computers\n",
        "# installs Apache Spark 2.4.7, Java 8, and Findspark, a library that makes it easy for Python to find Spark\n",
        "\n",
        "# 2) Second: set the locations where Spark and Java are installed to let know Colab where to find it.\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\"\n",
        "\n",
        "# 3) Third: import spark libraries and use them\n",
        "import findspark\n",
        "findspark.init(\"spark-3.1.2-bin-hadoop3.2\") # SPARK_HOME\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create the session - We need to remember to close it at the end\n",
        "# The session is basically our connection to Spark layer in the Hadoop ecosystem\n",
        "spark = SparkSession.builder.appName(\"walmart\").getOrCreate()\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GLm8Xm7aNUi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as f"
      ],
      "metadata": {
        "id": "NXZ6cgAtjVgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N38I2z3aPDYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "SGjYGrmhEXz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "def split_column(df, col_name, col_delimiter=';', new_cols_names=None):\n",
        "  new_col_name = col_name.replace('\\\"', '').strip()\n",
        "  if new_cols_names is None:\n",
        "    new_cols = new_col_name.split(col_delimiter)\n",
        "    new_cols = [c.replace('-', '_').lower() for c in new_cols]\n",
        "    new_col_exprs = [f'`{new_col_name}`[{i}] as `{new_cols[i]}`' for i in range(len(new_cols))]\n",
        "  else:\n",
        "    new_col_exprs = [f'`{new_col_name}`[{i}] as `{new_cols_names[i]}`' for i in range(len(new_cols_names))]\n",
        "\n",
        "  new_df = df.select(*[c for c in df.columns if c != col_name], F.split(col_name, col_delimiter).alias(new_col_name))\\\n",
        "    .selectExpr('*', *new_col_exprs)\n",
        "  \n",
        "  return new_df.select(*[c for c in new_df.columns if c != new_col_name])\n",
        "    \n",
        "def remove_prefix(df, columns, prefix='\\\"'):\n",
        "  return df.selectExpr(*[c for c in df.columns if c not in columns], *[f'regexp_replace({c}, \\'^{prefix}\\', \\'\\') as {c}' for c in columns])\n",
        "\n",
        "def remove_suffix(df, columns, suffix='\\\"'):\n",
        "  return df.selectExpr(*[c for c in df.columns if c not in columns], *[f'regexp_replace({c}, \\'{suffix}$\\', \\'\\') as {c}' for c in columns])"
      ],
      "metadata": {
        "id": "qrhQeaaZEda3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "03kIFx-yPE6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V7P-bdp4O_Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading & Processing"
      ],
      "metadata": {
        "id": "R9UqmNW3Euis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kmcaRg0krLU",
        "outputId": "02f76132-988c-4895-eccb-b2f955745d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "books_rating_df = spark.read.csv('/content/drive/MyDrive/BDA/big data project/BX-Book-Ratings.csv', sep=';', header=True, inferSchema=True)\n",
        "books_rating_clean_df = split_column(books_rating_df, books_rating_df.columns[0])\\\n",
        "      .selectExpr('user_id', 'isbn', '`\"\"Book-Rating\"\"\",,` as book_rating')\n",
        "books_rating_clean_df = remove_prefix(books_rating_clean_df, columns=['user_id'])\n",
        "books_rating_clean_df = remove_prefix(books_rating_clean_df, columns=['isbn', 'book_rating'], prefix='\\\"\\\"')\n",
        "books_rating_clean_df = remove_suffix(books_rating_clean_df, columns=['isbn'], suffix='\\\"\\\"')\n",
        "books_rating_clean_df = remove_suffix(books_rating_clean_df, columns=['book_rating'], suffix='\\\"\\\"\\\",,')\n",
        "books_rating_clean_df = books_rating_clean_df.selectExpr('int(user_id) as user_id', 'isbn', 'int(book_rating) as book_rating')\n",
        "books_rating_clean_df = books_rating_clean_df.select(f.regexp_replace (f.col(\"user_id\"), \"[^0-9]\", \"\").alias(\"user_id\"), \"isbn\", \"book_rating\")\n",
        "books_rating_clean_df = books_rating_clean_df.select(f.regexp_replace (f.col(\"isbn\"), \"[^0-9x]\", \"\").alias(\"isbn\"), \"user_id\", \"book_rating\")\n",
        "books_rating_clean_df = books_rating_clean_df.where (\"length(isbn) =10 or length(isbn) = 13\") \n",
        "\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        " \n",
        "books_rating_clean_df = books_rating_clean_df.withColumn('isbn', trim(books_rating_clean_df.isbn))\n",
        "\n",
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "def blank_as_null(x):\n",
        "    return when(col(x) != \"\", col(x)).otherwise(None)\n",
        "\n",
        "books_rating_clean_df = books_rating_clean_df.withColumn(\"isbn\", blank_as_null(\"isbn\"))\n",
        "\n",
        "books_rating_clean_df = books_rating_clean_df.na.fill({\"book_rating\": \"0\" }) \n",
        "\n",
        "\n",
        "books_rating_clean_df.printSchema()\n",
        "books_rating_clean_df.show()\n"
      ],
      "metadata": {
        "id": "BjCGg7CUk7aw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3749e617-fb86-4244-97f7-a8b739ce529b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- isbn: string (nullable = true)\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- book_rating: integer (nullable = true)\n",
            "\n",
            "+----------+-------+-----------+\n",
            "|      isbn|user_id|book_rating|\n",
            "+----------+-------+-----------+\n",
            "|0155061224| 276726|          5|\n",
            "|0446520802| 276727|          0|\n",
            "|0521795028| 276729|          6|\n",
            "|2080674722| 276733|          0|\n",
            "|3257224281| 276736|          8|\n",
            "|0600570967| 276737|          6|\n",
            "|0425115801| 276746|          0|\n",
            "|0449006522| 276746|          0|\n",
            "|0553561618| 276746|          0|\n",
            "|0786013990| 276746|          0|\n",
            "|0786014512| 276746|          0|\n",
            "|0060517794| 276747|          9|\n",
            "|0451192001| 276747|          0|\n",
            "|0609801279| 276747|          0|\n",
            "|0671537458| 276747|          9|\n",
            "|0679776818| 276747|          8|\n",
            "|0943066433| 276747|          7|\n",
            "|1570231028| 276747|          0|\n",
            "|1885408226| 276747|          7|\n",
            "|0747558167| 276748|          6|\n",
            "+----------+-------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "books_df = spark.read.csv('/content/drive/MyDrive/BDA/big data project/BX-Books.csv', sep=';', header=True, inferSchema=True)\n",
        "books_clean_df = books_df.selectExpr('ISBN as isbn', '`Book-Title` as book_title', '`Book-Author` as book_author',\n",
        "                                     'int(`Year-Of-Publication`) as year_of_publication', 'Publisher as publisher')\n",
        "books_clean_df = books_clean_df.select(f.regexp_replace (f.col(\"isbn\"), \"[^0-9x]\", \"\").alias(\"isbn\"),\"year_of_publication\", \"book_title\", \"book_author\", \"publisher\")\n",
        "books_clean_df = books_clean_df.selectExpr (\"isbn\",\"book_title\",\"book_author\",\"CASE WHEN year_of_publication = 0  THEN '1900' ELSE year_of_publication END as year_of_publication\",\"publisher\")\n",
        "\n",
        "from pyspark.sql.functions import udf\n",
        "\n",
        "def ascii_ignore(x):\n",
        "    return x.encode('ascii', 'ignore').decode('ascii')\n",
        "\n",
        "ascii_udf = udf(ascii_ignore)\n",
        "\n",
        "\n",
        "\n",
        "books_clean_df = books_clean_df.withColumn(\"book_title\", ascii_udf('book_title'))\n",
        "books_clean_df = books_clean_df.withColumn(\"book_author\", ascii_udf('book_author'))\n",
        "books_clean_df = books_clean_df.withColumn(\"publisher\", ascii_udf('publisher'))\n",
        "\n",
        "\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], prefix='@')\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], prefix='\\$')\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], prefix='-')\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], prefix='-')\n",
        "books_clean_df = remove_suffix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], suffix='@')\n",
        "books_clean_df = remove_suffix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], suffix='-')\n",
        "\n",
        "books_clean_df = remove_suffix(books_clean_df, columns=['book_author', 'publisher'], suffix='\\\\\\?')\n",
        "books_clean_df = remove_suffix(books_clean_df, columns=['book_author', 'publisher'], suffix='\"')\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_author', 'publisher'], prefix='\"')\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_author', 'publisher'], prefix='\\\\\\?')\n",
        "\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], prefix='@')\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], prefix='\\$')\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], prefix='-')\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], prefix='-')\n",
        "books_clean_df = remove_suffix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], suffix='@')\n",
        "books_clean_df = remove_suffix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], suffix='-')\n",
        "\n",
        "books_clean_df = remove_suffix(books_clean_df, columns=['book_author', 'publisher'], suffix='\\\\\\?')\n",
        "books_clean_df = remove_suffix(books_clean_df, columns=['book_author', 'publisher'], suffix='\"')\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_author', 'publisher'], prefix='\"')\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_author', 'publisher'], prefix='\\\\\\?')\n",
        "\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], prefix='@')\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], prefix='\\$')\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], prefix='-')\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], prefix='-')\n",
        "books_clean_df = remove_suffix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], suffix='@')\n",
        "books_clean_df = remove_suffix(books_clean_df, columns=['book_title', 'book_author', 'publisher'], suffix='-')\n",
        "\n",
        "books_clean_df = remove_suffix(books_clean_df, columns=['book_author', 'publisher'], suffix='\\\\\\?')\n",
        "books_clean_df = remove_suffix(books_clean_df, columns=['book_author', 'publisher'], suffix='\"')\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_author', 'publisher'], prefix='\"')\n",
        "books_clean_df = remove_prefix(books_clean_df, columns=['book_author', 'publisher'], prefix='\\\\\\?')\n",
        "\n",
        "books_clean_df.printSchema()\n",
        "books_clean_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQvQ9K-oCCZr",
        "outputId": "c0f3a89b-f734-408e-94cb-7e957eff6020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- isbn: string (nullable = true)\n",
            " |-- year_of_publication: string (nullable = true)\n",
            " |-- book_title: string (nullable = true)\n",
            " |-- book_author: string (nullable = true)\n",
            " |-- publisher: string (nullable = true)\n",
            "\n",
            "+----------+-------------------+--------------------+--------------------+--------------------+\n",
            "|      isbn|year_of_publication|          book_title|         book_author|           publisher|\n",
            "+----------+-------------------+--------------------+--------------------+--------------------+\n",
            "|0195153448|               2002| Classical Mythology|  Mark P. O. Morford|Oxford University...|\n",
            "|0002005018|               2001|        Clara Callan|Richard Bruce Wright|HarperFlamingo Ca...|\n",
            "|0060973129|               1991|Decision in Normandy|        Carlo D'Este|     HarperPerennial|\n",
            "|0374157065|               1999|Flu: The Story of...|    Gina Bari Kolata|Farrar Straus Giroux|\n",
            "|0393045218|               1999|The Mummies of Ur...|     E. J. W. Barber|W. W. Norton &amp...|\n",
            "|0399135782|               1991|The Kitchen God's...|             Amy Tan|    Putnam Pub Group|\n",
            "|0425176428|               2000|What If?: The Wor...|       Robert Cowley|Berkley Publishin...|\n",
            "|0671870432|               1993|     PLEADING GUILTY|         Scott Turow|          Audioworks|\n",
            "|0679425608|               1996|Under the Black F...|     David Cordingly|        Random House|\n",
            "| 074322678|               2002|Where You'll Find...|         Ann Beattie|            Scribner|\n",
            "|0771074670|               1988|Nights Below Stat...|David Adams Richards|     Emblem Editions|\n",
            "| 080652121|               2000|Hitler's Secret B...|          Adam Lebor|       Citadel Press|\n",
            "|0887841740|               2004|  The Middle Stories|         Sheila Heti|House of Anansi P...|\n",
            "|1552041778|               1999|            Jane Doe|        R. J. Kaiser|          Mira Books|\n",
            "|1558746218|               1998|A Second Chicken ...|       Jack Canfield|Health Communicat...|\n",
            "|1567407781|               1998|The Witchfinder (...|   Loren D. Estleman|Brilliance Audio ...|\n",
            "|1575663937|               1999|More Cunning Than...|  Robert Hendrickson|Kensington Publis...|\n",
            "|1881320189|               1994|Goodbye to the Bu...|        Julia Oliver|      River City Pub|\n",
            "|0440234743|               1999|       The Testament|        John Grisham|                Dell|\n",
            "|0452264464|               1994|Beloved (Plume Co...|       Toni Morrison|               Plume|\n",
            "+----------+-------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "books_clean_df.filter(books_clean_df.isbn.isNull()).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbBe9PxsEwJM",
        "outputId": "997cce3a-8282-4e05-93e9-d68041bcd86f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------------+----------+-----------+---------+\n",
            "|isbn|year_of_publication|book_title|book_author|publisher|\n",
            "+----+-------------------+----------+-----------+---------+\n",
            "+----+-------------------+----------+-----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_df = spark.read.csv('/content/drive/MyDrive/BDA/big data project/BX-Users.csv', sep=';',header=True, inferSchema=True)\n",
        "users_clean_df = users_df.selectExpr('int(`User-ID`) as user_id', 'Location as location', 'int(Age) as age')\n",
        "users_clean_df = split_column(users_clean_df, 'location', col_delimiter=',', new_cols_names=['city', 'district', 'country'])\n",
        "users_clean_df = users_clean_df.selectExpr('user_id', \"CASE WHEN age > 120 or age < -1 THEN '-1' ELSE age END as age\",\n",
        "                                           \"regexp_replace(city, '[^a-zA-Z]+', '') as city\",\n",
        "                                           \"regexp_replace(district, '[^a-zA-Z]+', '') as district\",\n",
        "                                           \"CASE WHEN trim(country) = '' THEN 'unknown' ELSE trim(country) END as country\")\n",
        "users_clean_df = users_clean_df.selectExpr('user_id', 'age', \"CASE WHEN city = '' or city = 'na' THEN 'unknown' ELSE city END as city\",\n",
        "                                    \"CASE WHEN district = '' or district = 'na' THEN 'unknown' ELSE district END as district\",'country')\n",
        "\n",
        "countries_df = spark.read.csv('/content/drive/MyDrive/BDA/big data project/WORLD COUNTRIES.csv.xls', sep=';', header=False, inferSchema=True)\n",
        "countries_df = countries_df.select('_c0')\n",
        "countries_df = countries_df.selectExpr('lower(_c0) as country_output')\n",
        "\n",
        "users_clean_df = users_clean_df.join(countries_df, users_clean_df['country']==countries_df['country_output'], how='left')\\\n",
        "  .where(\"country = 'unknown' or country_output is not null\").select('user_id', 'age', 'city', 'district', 'country')\n",
        "\n",
        "\n",
        "users_clean_df = users_clean_df.withColumn('city', trim(users_clean_df.city))\n",
        "\n",
        "users_clean_df = users_clean_df.withColumn(\"city\", blank_as_null(\"city\"))\n",
        "\n",
        "users_clean_df = users_clean_df.withColumn('district', trim(users_clean_df.district))\n",
        "\n",
        "users_clean_df = users_clean_df.withColumn(\"district\", blank_as_null(\"district\"))\n",
        "\n",
        "users_clean_df = users_clean_df.na.fill({\"user_id\": \"-1\", \"age\": \"-1\",\"city\": \"unknown\",\"district\": \"unknown\", \"country\":\"unknown\" }) \n",
        "\n",
        "users_clean_df.printSchema()\n",
        "users_clean_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7b7YyBUDZGA",
        "outputId": "f4103d20-1b77-4189-ef06-623bddf13416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- age: string (nullable = false)\n",
            " |-- city: string (nullable = false)\n",
            " |-- district: string (nullable = false)\n",
            " |-- country: string (nullable = false)\n",
            "\n",
            "+-------+---+------------+--------------+--------------+\n",
            "|user_id|age|        city|      district|       country|\n",
            "+-------+---+------------+--------------+--------------+\n",
            "|      1| -1|         nyc|       newyork|           usa|\n",
            "|      2| 18|    stockton|    california|           usa|\n",
            "|      3| -1|      moscow|yukonterritory|        russia|\n",
            "|      4| 17|       porto|        vngaia|      portugal|\n",
            "|      5| -1| farnborough|         hants|united kingdom|\n",
            "|      6| 61| santamonica|    california|           usa|\n",
            "|      7| -1|  washington|            dc|           usa|\n",
            "|      8| -1|     timmins|       ontario|        canada|\n",
            "|      9| -1|  germantown|     tennessee|           usa|\n",
            "|     10| 26|    albacete|     wisconsin|         spain|\n",
            "|     11| 14|   melbourne|      victoria|     australia|\n",
            "|     12| -1|   fortbragg|    california|           usa|\n",
            "|     13| 26|   barcelona|     barcelona|         spain|\n",
            "|     14| -1|  mediapolis|          iowa|           usa|\n",
            "|     15| -1|     calgary|       alberta|        canada|\n",
            "|     16| -1| albuquerque|     newmexico|           usa|\n",
            "|     17| -1|  chesapeake|      virginia|           usa|\n",
            "|     18| 25|riodejaneiro|  riodejaneiro|        brazil|\n",
            "|     19| 14|      weston|       unknown|       unknown|\n",
            "|     20| 19|   langhorne|  pennsylvania|           usa|\n",
            "+-------+---+------------+--------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_clean_df.filter(users_clean_df.city.isNull() | (users_clean_df.city == \"\") | (users_clean_df.district == \"\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgUIEQd7TkjU",
        "outputId": "2850283a-8213-4868-afbb-32db18b7f2cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----+--------+-------+\n",
            "|user_id|age|city|district|country|\n",
            "+-------+---+----+--------+-------+\n",
            "+-------+---+----+--------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_clean_df.where(\"city = 'na'\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV7AvjEMLS7Q",
        "outputId": "1f0d104b-97d7-4526-d55f-0eb1da19779e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----+--------+-------+\n",
            "|user_id|age|city|district|country|\n",
            "+-------+---+----+--------+-------+\n",
            "+-------+---+----+--------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "books_rating_clean_df.toPandas().to_csv(\"books_rating_clean_df.csv\", sep=';', index = False)\n",
        "books_clean_df.toPandas().to_csv(\"books_clean_df.csv\", sep=';', index = False)\n",
        "users_clean_df.toPandas().to_csv(\"user_clean_df.csv\", sep=';', index = False)"
      ],
      "metadata": {
        "id": "b5x6TsRdnjMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "VmJsUFVzUSRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pOepOty2XQ6Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}